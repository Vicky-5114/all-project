{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6462e3c8-5339-4797-8696-2fc591a0be96",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf8840f-8fca-4155-9268-51b7297b109a",
   "metadata": {},
   "source": [
    "Dataset: MNIST  \n",
    "Each piece of data is a 28*28(784 features) grayscale image of a handwritten digit. Training-set includes 60000 images; Test-set includes 10000 images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953dae29-1e29-446f-8333-57f99641fe16",
   "metadata": {},
   "source": [
    "Number of input layer neuron: 784 (size: 28*28)    \n",
    "Number of output layer neuron: 10 (class: 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4293cc6-90fe-460c-9eb0-6182ceb42f54",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b89533bb-26b4-4b15-897c-f83ee16c5811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6063d6e-de76-4b08-b341-317056030d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read .csv files to load data\n",
    "train_path = \"mnist_train.csv\"\n",
    "test_path = \"mnist_test.csv\"\n",
    "train_data = pd.read_csv(train_path,header=None)\n",
    "test_data = pd.read_csv(test_path,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc99405-1b07-43de-a419-ee47118d482f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785)\n",
      "(10000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5b97244d-1634-4c6d-984a-ab74c7ea8cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data.iloc[:, 0].values  # get labels\n",
    "x_train = train_data.iloc[:, 1:].values / 255.0  # get features\n",
    "\n",
    "y_test = test_data.iloc[:, 0].values  # get labels\n",
    "x_test = test_data.iloc[:, 1:].values / 255.0  # get features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d0ccb74-9383-48fa-a9dd-c2929df1c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensor\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6751431e-f1ce-456e-a8df-45e542400b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 784])\n",
      "torch.Size([60000])\n",
      "torch.Size([10000, 784])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75620b0f-69e9-44ad-93c9-4e514fe54126",
   "metadata": {},
   "source": [
    "### Building Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fc085452-17be-4a60-a77c-0c5317cc0b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0d61817b-7513-428e-8dfe-1657ea59e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ce0e7618-1203-4c6f-9453-5b01ed529df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 500)\n",
    "        self.fc3 = nn.Linear(500, 10)\n",
    "        # input 784 features >>> 1000 neurons >>> 500 neurons >>> output 10 classes\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))  # use \"relu\" activation function\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "357def2b-208a-4072-a39b-ee8784cef859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST(\n",
      "  (fc1): Linear(in_features=784, out_features=1000, bias=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=500, bias=True)\n",
      "  (fc3): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mnist = MNIST().to(device) # instantiation\n",
    "print(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ec5f8943-2371-4fbe-b76d-60b1063d6c66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 13.138396263122559\n",
      "Epoch 1, Loss: 15.532133102416992\n",
      "Epoch 2, Loss: 16.90188980102539\n",
      "Epoch 3, Loss: 16.443052291870117\n",
      "Epoch 4, Loss: 9.296648025512695\n",
      "Epoch 5, Loss: 6.8345136642456055\n",
      "Epoch 6, Loss: 2.460996389389038\n",
      "Epoch 7, Loss: 1.5471001863479614\n",
      "Epoch 8, Loss: 1.785235047340393\n",
      "Epoch 9, Loss: 1.0998437404632568\n",
      "Epoch 10, Loss: 0.9675479531288147\n",
      "Epoch 11, Loss: 0.9238576292991638\n",
      "Epoch 12, Loss: 0.8884881138801575\n",
      "Epoch 13, Loss: 0.857928454875946\n",
      "Epoch 14, Loss: 0.8308229446411133\n",
      "Epoch 15, Loss: 0.8066513538360596\n",
      "Epoch 16, Loss: 0.7849944233894348\n",
      "Epoch 17, Loss: 0.7654323577880859\n",
      "Epoch 18, Loss: 0.7476842403411865\n",
      "Epoch 19, Loss: 0.7314475178718567\n",
      "Epoch 20, Loss: 0.7165075540542603\n",
      "Epoch 21, Loss: 0.7026445269584656\n",
      "Epoch 22, Loss: 0.6897234320640564\n",
      "Epoch 23, Loss: 0.6776250600814819\n",
      "Epoch 24, Loss: 0.666257381439209\n",
      "Epoch 25, Loss: 0.6555370688438416\n",
      "Epoch 26, Loss: 0.6454069018363953\n",
      "Epoch 27, Loss: 0.6358129978179932\n",
      "Epoch 28, Loss: 0.6267023682594299\n",
      "Epoch 29, Loss: 0.6180256605148315\n",
      "Epoch 30, Loss: 0.6097457408905029\n",
      "Epoch 31, Loss: 0.6018334031105042\n",
      "Epoch 32, Loss: 0.5942609906196594\n",
      "Epoch 33, Loss: 0.5870099663734436\n",
      "Epoch 34, Loss: 0.5800483226776123\n",
      "Epoch 35, Loss: 0.57335364818573\n",
      "Epoch 36, Loss: 0.5669152736663818\n",
      "Epoch 37, Loss: 0.5607103109359741\n",
      "Epoch 38, Loss: 0.5547208189964294\n",
      "Epoch 39, Loss: 0.5489374995231628\n",
      "Epoch 40, Loss: 0.5433418154716492\n",
      "Epoch 41, Loss: 0.5379254817962646\n",
      "Epoch 42, Loss: 0.5326871275901794\n",
      "Epoch 43, Loss: 0.527616024017334\n",
      "Epoch 44, Loss: 0.5226977467536926\n",
      "Epoch 45, Loss: 0.5179256200790405\n",
      "Epoch 46, Loss: 0.5132928490638733\n",
      "Epoch 47, Loss: 0.5087931752204895\n",
      "Epoch 48, Loss: 0.5044160485267639\n",
      "Epoch 49, Loss: 0.5001567602157593\n",
      "Epoch 50, Loss: 0.49601057171821594\n",
      "Epoch 51, Loss: 0.49197685718536377\n",
      "Epoch 52, Loss: 0.4880489706993103\n",
      "Epoch 53, Loss: 0.48421943187713623\n",
      "Epoch 54, Loss: 0.4804849922657013\n",
      "Epoch 55, Loss: 0.4768405854701996\n",
      "Epoch 56, Loss: 0.47328269481658936\n",
      "Epoch 57, Loss: 0.46980559825897217\n",
      "Epoch 58, Loss: 0.46640828251838684\n",
      "Epoch 59, Loss: 0.4630863666534424\n",
      "Epoch 60, Loss: 0.45983701944351196\n",
      "Epoch 61, Loss: 0.4566572904586792\n",
      "Epoch 62, Loss: 0.45354554057121277\n",
      "Epoch 63, Loss: 0.45050013065338135\n",
      "Epoch 64, Loss: 0.4475172162055969\n",
      "Epoch 65, Loss: 0.4445946514606476\n",
      "Epoch 66, Loss: 0.4417324364185333\n",
      "Epoch 67, Loss: 0.4389277398586273\n",
      "Epoch 68, Loss: 0.4361792504787445\n",
      "Epoch 69, Loss: 0.4334834814071655\n",
      "Epoch 70, Loss: 0.43084004521369934\n",
      "Epoch 71, Loss: 0.42824587225914\n",
      "Epoch 72, Loss: 0.4256981313228607\n",
      "Epoch 73, Loss: 0.42319878935813904\n",
      "Epoch 74, Loss: 0.4207445979118347\n",
      "Epoch 75, Loss: 0.4183324873447418\n",
      "Epoch 76, Loss: 0.415962278842926\n",
      "Epoch 77, Loss: 0.4136316776275635\n",
      "Epoch 78, Loss: 0.4113406836986542\n",
      "Epoch 79, Loss: 0.40908804535865784\n",
      "Epoch 80, Loss: 0.4068729877471924\n",
      "Epoch 81, Loss: 0.40469419956207275\n",
      "Epoch 82, Loss: 0.40255051851272583\n",
      "Epoch 83, Loss: 0.40043875575065613\n",
      "Epoch 84, Loss: 0.39835822582244873\n",
      "Epoch 85, Loss: 0.39630791544914246\n",
      "Epoch 86, Loss: 0.394289493560791\n",
      "Epoch 87, Loss: 0.39230117201805115\n",
      "Epoch 88, Loss: 0.3903442323207855\n",
      "Epoch 89, Loss: 0.3884161114692688\n",
      "Epoch 90, Loss: 0.38651612401008606\n",
      "Epoch 91, Loss: 0.3846435248851776\n",
      "Epoch 92, Loss: 0.38279932737350464\n",
      "Epoch 93, Loss: 0.38098201155662537\n",
      "Epoch 94, Loss: 0.37919074296951294\n",
      "Epoch 95, Loss: 0.37742555141448975\n",
      "Epoch 96, Loss: 0.37568509578704834\n",
      "Epoch 97, Loss: 0.3739677667617798\n",
      "Epoch 98, Loss: 0.37227320671081543\n",
      "Epoch 99, Loss: 0.370601624250412\n"
     ]
    }
   ],
   "source": [
    "# define learning rate\n",
    "lr = 0.001\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    x_train = x_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    y_pred = mnist(x_train)\n",
    "    \n",
    "    # calculate the loss\n",
    "    loss = F.cross_entropy(y_pred, y_train)\n",
    "\n",
    "    # backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Updating the gradient\n",
    "    with torch.no_grad():\n",
    "        for p in mnist.parameters():\n",
    "            p -= lr * p.grad\n",
    "        mnist.zero_grad() # Avoid gradient accumulation\n",
    "        \n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "        losses.append(loss.item())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf5cf40-9233-401e-9cf7-116974a208eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 89.72%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x_test = x_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "\n",
    "    y_test_pred = mnist(x_test)  \n",
    "    _, predicted = torch.max(y_test_pred, 1)  ß\n",
    "    correct = (predicted == y_test).sum().item()  \n",
    "    accuracy = correct / len(y_test)  \n",
    "    print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d51b43-ff0e-46ed-8409-82747b4d5733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.10",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
